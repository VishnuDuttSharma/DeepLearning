{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# We'll use Keras (included with TensorFlow) to import the data\n",
    "# I figured I'd do all the preprocessing and reshaping here, \n",
    "# rather than in the model.\n",
    "(x_train, y_train), (x_test, y_test) = tf.contrib.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "# Normalize the color values to 0-1\n",
    "# (as imported, they're 0-255)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Flatten 28x28 images to (784,)\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)\n",
    "\n",
    "# Convert to one-hot.\n",
    "y_train = tf.contrib.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.contrib.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of neurons in each hidden layer\n",
    "HIDDEN1_SIZE = 500\n",
    "HIDDEN2_SIZE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # First we'll create 2 fully-connected layers, with ReLU activations.\n",
    "    # Notice we're retrieving the 'x' feature (we'll provide this in the input function\n",
    "    # in a moment).\n",
    "    fc1 = tf.layers.dense(features['x'], HIDDEN1_SIZE, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc2 = tf.layers.dense(fc1, HIDDEN2_SIZE, activation=tf.nn.relu, name=\"fc2\")\n",
    "    \n",
    "    # Add dropout operation; 0.9 probability that a neuron will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=fc2, rate=0.1, training = mode == tf.estimator.ModeKeys.TRAIN, name=\"dropout\")\n",
    "\n",
    "    # Finally, we'll calculate logits. This will be\n",
    "    # the input to our Softmax function. Notice we \n",
    "    # don't apply an activation at this layer.\n",
    "    # If you've commented out the dropout layer,\n",
    "    # switch the input here to 'fc2'.\n",
    "    logits = tf.layers.dense(dropout, units=10, name=\"logits\")\n",
    "    \n",
    "    # Generate Predictions\n",
    "    classes = tf.argmax(logits, axis=1)\n",
    "    predictions = {\n",
    "        'classes': classes,\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Return an EstimatorSpec for prediction\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "    # Compute the loss, per usual.\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=labels, logits=logits)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        # Configure the Training Op\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=1e-3,\n",
    "            optimizer='Adam')\n",
    "\n",
    "        # Return an EstimatorSpec for training\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
    "                                      loss=loss, train_op=train_op)    \n",
    "\n",
    "    assert mode == tf.estimator.ModeKeys.EVAL\n",
    "    \n",
    "    # Configure the accuracy metric for evaluation\n",
    "    metrics = {'accuracy': tf.metrics.accuracy(classes, tf.argmax(labels, axis=1))}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, \n",
    "                                      predictions=predictions, \n",
    "                                      loss=loss,\n",
    "                                      eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    {'x': x_train},\n",
    "    y_train, \n",
    "    num_epochs=None, # repeat forever\n",
    "    shuffle=True # \n",
    ")\n",
    "\n",
    "test_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    {'x': x_test},\n",
    "    y_test,\n",
    "    num_epochs=1, # loop through the dataset once\n",
    "    shuffle=False # don't shuffle the test data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Vishnu\\AppData\\Local\\Temp\\tmpo_nmjhl5\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Vishnu\\\\AppData\\\\Local\\\\Temp\\\\tmpo_nmjhl5', '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_session_config': None, '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': 1}\n"
     ]
    }
   ],
   "source": [
    "# At this point, our Estimator will work just like a canned one.\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Vishnu\\AppData\\Local\\Temp\\tmpo_nmjhl5\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.33338, step = 1\n",
      "INFO:tensorflow:global_step/sec: 105.868\n",
      "INFO:tensorflow:loss = 0.380737, step = 101 (0.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.932\n",
      "INFO:tensorflow:loss = 0.22254, step = 201 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.992\n",
      "INFO:tensorflow:loss = 0.103807, step = 301 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.691\n",
      "INFO:tensorflow:loss = 0.129027, step = 401 (0.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.2401\n",
      "INFO:tensorflow:loss = 0.131172, step = 501 (2.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9195\n",
      "INFO:tensorflow:loss = 0.0980707, step = 601 (3.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1338\n",
      "INFO:tensorflow:loss = 0.105975, step = 701 (1.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.169\n",
      "INFO:tensorflow:loss = 0.0799317, step = 801 (0.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.909\n",
      "INFO:tensorflow:loss = 0.078832, step = 901 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.3681\n",
      "INFO:tensorflow:loss = 0.039535, step = 1001 (1.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.423\n",
      "INFO:tensorflow:loss = 0.0690954, step = 1101 (3.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1187\n",
      "INFO:tensorflow:loss = 0.0183258, step = 1201 (2.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.139\n",
      "INFO:tensorflow:loss = 0.0768624, step = 1301 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.041\n",
      "INFO:tensorflow:loss = 0.0235509, step = 1401 (0.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.663\n",
      "INFO:tensorflow:loss = 0.0217953, step = 1501 (0.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5475\n",
      "INFO:tensorflow:loss = 0.0409228, step = 1601 (3.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.6822\n",
      "INFO:tensorflow:loss = 0.0258086, step = 1701 (3.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.578\n",
      "INFO:tensorflow:loss = 0.0392141, step = 1801 (0.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.009\n",
      "INFO:tensorflow:loss = 0.0195446, step = 1901 (0.878 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\Vishnu\\AppData\\Local\\Temp\\tmpo_nmjhl5\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0252122.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x15bae876dd8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the estimator using our input function.\n",
    "estimator.train(input_fn=train_input, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-10-17-18:38:13\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Vishnu\\AppData\\Local\\Temp\\tmpo_nmjhl5\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-17-18:38:14\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9735, global_step = 2000, loss = 0.0874876\n",
      "{'accuracy': 0.97350001, 'loss': 0.087487601, 'global_step': 2000}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the estimator using our input function.\n",
    "# We should see our accuracy metric below\n",
    "evaluation = estimator.evaluate(input_fn=test_input)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Vishnu\\AppData\\Local\\Temp\\tmpo_nmjhl5\\model.ckpt-2000\n",
      "Example 0. True: 7, Predicted: 7\n",
      "Example 1. True: 2, Predicted: 2\n",
      "Example 2. True: 1, Predicted: 1\n",
      "Example 3. True: 0, Predicted: 0\n",
      "Example 4. True: 4, Predicted: 4\n"
     ]
    }
   ],
   "source": [
    "MAX_TO_PRINT = 5\n",
    "\n",
    "# This returns a generator object\n",
    "predictions = estimator.predict(input_fn=test_input)\n",
    "i = 0\n",
    "for p in predictions:\n",
    "    true_label = np.argmax(y_test[i])\n",
    "    predicted_label = p['classes']\n",
    "    print(\"Example %d. True: %d, Predicted: %s\" % (i, true_label, predicted_label))\n",
    "    i += 1\n",
    "    if i == MAX_TO_PRINT: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
