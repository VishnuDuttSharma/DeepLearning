{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation\n",
    "# from keras.layers import LSTM\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ptb_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, vocab = ptb_reader.ptb_raw_data(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = sorted(list(set(train_data)))\n",
    "V = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def one_hot(x, y, sentence_len):\n",
    "#     imat = np.zeros((x.shape[0], sentence_len, V))\n",
    "#     for j in range(x.shape[1]):\n",
    "#         for i in zip(range(sentence_len), x[j]):\n",
    "#             imat[j, i[0], i[1]] = 1\n",
    "#     omat = np.zeros((x.shape[0], V))\n",
    "#     for j in range(x.shape[0]):\n",
    "#         omat[j, y[j]] = 1\n",
    "#     return imat, omat\n",
    "\n",
    "def one_hot(x, y, sentence_len):\n",
    "    omat = np.zeros((x.shape[0], V))\n",
    "    for j in range(x.shape[0]):\n",
    "        omat[j, y[j]] = 1\n",
    "    return omat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create place holders\n",
    "embedding_size = 300\n",
    "with tf.variable_scope('model1'):\n",
    "    data = tf.placeholder(tf.int32, [None, seq_len])\n",
    "    target = tf.placeholder(tf.float32, [None, V])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model1'):\n",
    "    # Get embedding\n",
    "    embedding = tf.get_variable('embedding', [V, embedding_size])\n",
    "    inputs = tf.nn.embedding_lookup(embedding, data)\n",
    "    inputs = tf.nn.dropout(inputs, keep_prob = 0.5)\n",
    "    # create lstm cell\n",
    "    num_hidden = 128\n",
    "    lstm_unit = lambda: tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm_unit() for _ in range(3)], state_is_tuple=True)\n",
    "    \n",
    "    # pass through lstm\n",
    "    val, state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "\n",
    "    # get lstm output\n",
    "    val = tf.transpose(val, [1, 0, 2])\n",
    "    last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "\n",
    "    # pass lstm output to nn\n",
    "    weight = tf.Variable(tf.truncated_normal([num_hidden, int(target.get_shape()[1])]))\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[target.get_shape()[1]]))\n",
    "\n",
    "    # final nn output\n",
    "    predict = tf.nn.softmax(tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'labels' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-60bde7bb70f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_seq2seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_loss_by_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mminimize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishnu\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\contrib\\legacy_seq2seq\\python\\ops\\seq2seq.py\u001b[0m in \u001b[0;36msequence_loss_by_example\u001b[1;34m(logits, targets, weights, average_across_timesteps, softmax_loss_function, name)\u001b[0m\n\u001b[0;32m   1063\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m-> 1065\u001b[1;33m             labels=target, logits=logit)\n\u001b[0m\u001b[0;32m   1066\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[0mcrossent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_loss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishnu\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1712\u001b[0m       cost, _ = gen_nn_ops._sparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m-> 1713\u001b[1;33m           precise_logits, labels, name=name)\n\u001b[0m\u001b[0;32m   1714\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishnu\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m_sparse_softmax_cross_entropy_with_logits\u001b[1;34m(features, labels, name)\u001b[0m\n\u001b[0;32m   2376\u001b[0m   \"\"\"\n\u001b[0;32m   2377\u001b[0m   result = _op_def_lib.apply_op(\"SparseSoftmaxCrossEntropyWithLogits\",\n\u001b[1;32m-> 2378\u001b[1;33m                                 features=features, labels=labels, name=name)\n\u001b[0m\u001b[0;32m   2379\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseSoftmaxCrossEntropyWithLogitsOutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishnu\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    583\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    584\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    586\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Vishnu\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     59\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 61\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'labels' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('model1'):\n",
    "    # Cross entropy loss\n",
    "#     loss = -tf.reduce_sum(target*tf.log(tf.clip_by_value(predict, 1e-10, 1.0)))\n",
    "    batch_size, num_steps = 100, seq_len\n",
    "    weights = tf.ones([batch_size * num_steps])\n",
    "    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([predict], [target],[weights], V)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    minimize = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model1'):\n",
    "    # evaluations\n",
    "    corrects = tf.equal(tf.argmax(predict, 1), tf.argmax(target, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('model1'):\n",
    "    # initialization\n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create session and init variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create session\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saver.restore(sess, \"saved_model/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10\n",
      "0. Training Accuracy: 33.00 %\n",
      "0. Training Perplexity: 3.3788477197243498e+100\n",
      "\n",
      "20. Training Accuracy: 81.00 %\n",
      "20. Training Perplexity: 1.293902553423465e+26\n",
      "\n",
      "40. Training Accuracy: 79.00 %\n",
      "40. Training Perplexity: 8.261632261424608e+26\n",
      "\n",
      "60. Training Accuracy: 76.00 %\n",
      "60. Training Perplexity: 2.2276774027109597e+29\n",
      "\n",
      "80. Training Accuracy: 86.00 %\n",
      "80. Training Perplexity: 6.717637989829769e+18\n",
      "\n",
      "100. Training Accuracy: 81.00 %\n",
      "100. Training Perplexity: 1.2938376775849196e+24\n",
      "\n",
      "120. Training Accuracy: 80.00 %\n",
      "120. Training Perplexity: 2.359612992432006e+26\n",
      "\n",
      "140. Training Accuracy: 86.00 %\n",
      "140. Training Perplexity: 1.2363047151704631e+23\n",
      "\n",
      "160. Training Accuracy: 88.00 %\n",
      "160. Training Perplexity: 1.8261116556881136e+19\n",
      "\n",
      "180. Training Accuracy: 78.00 %\n",
      "180. Training Perplexity: 1.9438461203388803e+24\n",
      "\n",
      "200. Training Accuracy: 82.00 %\n",
      "200. Training Perplexity: 6.785393024462755e+23\n",
      "\n",
      "220. Training Accuracy: 95.00 %\n",
      "220. Training Perplexity: 5.899869049018289e+18\n",
      "\n",
      "240. Training Accuracy: 69.00 %\n",
      "240. Training Perplexity: 3.1032884987681837e+38\n",
      "\n",
      "260. Training Accuracy: 76.00 %\n",
      "260. Training Perplexity: 1.7501510429932278e+33\n",
      "\n",
      "280. Training Accuracy: 67.00 %\n",
      "280. Training Perplexity: 1.3176156370889329e+35\n",
      "\n",
      "300. Training Accuracy: 74.00 %\n",
      "300. Training Perplexity: 1.0314084084771045e+41\n",
      "\n",
      "320. Training Accuracy: 69.00 %\n",
      "320. Training Perplexity: 2.030499430278886e+37\n",
      "\n",
      "340. Training Accuracy: 71.00 %\n",
      "340. Training Perplexity: 1.302893313926352e+36\n",
      "\n",
      "360. Training Accuracy: 68.00 %\n",
      "360. Training Perplexity: 3.459905496367845e+37\n",
      "\n",
      "380. Training Accuracy: 74.00 %\n",
      "380. Training Perplexity: 6.985314661908152e+27\n",
      "\n",
      "400. Training Accuracy: 81.00 %\n",
      "400. Training Perplexity: 1.358153265633187e+31\n",
      "\n",
      "420. Training Accuracy: 82.00 %\n",
      "420. Training Perplexity: 4.316492458252824e+27\n",
      "\n",
      "440. Training Accuracy: 67.00 %\n",
      "440. Training Perplexity: 7.243403263578704e+38\n",
      "\n",
      "460. Training Accuracy: 63.00 %\n",
      "460. Training Perplexity: 4.836626351293913e+41\n",
      "\n",
      "Epoch: 1/10\n",
      "0. Training Accuracy: 72.00 %\n",
      "0. Training Perplexity: 3.254807347395948e+23\n",
      "\n",
      "20. Training Accuracy: 79.00 %\n",
      "20. Training Perplexity: 3.0937458610688115e+24\n",
      "\n",
      "40. Training Accuracy: 79.00 %\n",
      "40. Training Perplexity: 7.352968685544601e+21\n",
      "\n",
      "60. Training Accuracy: 75.00 %\n",
      "60. Training Perplexity: 4.9960940701613436e+29\n",
      "\n",
      "80. Training Accuracy: 82.00 %\n",
      "80. Training Perplexity: 8.145187985914316e+21\n",
      "\n",
      "100. Training Accuracy: 82.00 %\n",
      "100. Training Perplexity: 1.655429243616894e+26\n",
      "\n",
      "120. Training Accuracy: 81.00 %\n",
      "120. Training Perplexity: 1.8837661170137888e+29\n",
      "\n",
      "140. Training Accuracy: 82.00 %\n",
      "140. Training Perplexity: 2.034948783530698e+20\n",
      "\n",
      "160. Training Accuracy: 89.00 %\n",
      "160. Training Perplexity: 110695303429853.27\n",
      "\n",
      "180. Training Accuracy: 80.00 %\n",
      "180. Training Perplexity: 1.529030977260201e+25\n",
      "\n",
      "200. Training Accuracy: 84.00 %\n",
      "200. Training Perplexity: 2.764163194040909e+25\n",
      "\n",
      "220. Training Accuracy: 78.00 %\n",
      "220. Training Perplexity: 5.2860477888724e+24\n",
      "\n",
      "240. Training Accuracy: 72.00 %\n",
      "240. Training Perplexity: 1.1410840843398027e+24\n",
      "\n",
      "260. Training Accuracy: 78.00 %\n",
      "260. Training Perplexity: 1.1614287924566063e+23\n",
      "\n",
      "280. Training Accuracy: 74.00 %\n",
      "280. Training Perplexity: 1.6219407625923817e+32\n",
      "\n",
      "300. Training Accuracy: 77.00 %\n",
      "300. Training Perplexity: 1.4480954096570234e+29\n",
      "\n",
      "320. Training Accuracy: 77.00 %\n",
      "320. Training Perplexity: 5.888394492479834e+32\n",
      "\n",
      "340. Training Accuracy: 70.00 %\n",
      "340. Training Perplexity: 6.32245879015506e+34\n",
      "\n",
      "360. Training Accuracy: 80.00 %\n",
      "360. Training Perplexity: 9.126933150154887e+28\n",
      "\n",
      "380. Training Accuracy: 83.00 %\n",
      "380. Training Perplexity: 1.2969343018985882e+20\n",
      "\n",
      "400. Training Accuracy: 84.00 %\n",
      "400. Training Perplexity: 1.568952273713638e+24\n",
      "\n",
      "420. Training Accuracy: 74.00 %\n",
      "420. Training Perplexity: 3.4039782174910927e+22\n",
      "\n",
      "440. Training Accuracy: 67.00 %\n",
      "440. Training Perplexity: 6.001276346269518e+35\n",
      "\n",
      "460. Training Accuracy: 72.00 %\n",
      "460. Training Perplexity: 4.022106390636741e+34\n",
      "\n",
      "Epoch: 2/10\n",
      "0. Training Accuracy: 80.00 %\n",
      "0. Training Perplexity: 2.27272004994202e+22\n",
      "\n",
      "20. Training Accuracy: 87.00 %\n",
      "20. Training Perplexity: 2.409762233683774e+21\n",
      "\n",
      "40. Training Accuracy: 79.00 %\n",
      "40. Training Perplexity: 8.735559714614943e+21\n",
      "\n",
      "60. Training Accuracy: 79.00 %\n",
      "60. Training Perplexity: 3.6132106727852438e+22\n",
      "\n",
      "80. Training Accuracy: 79.00 %\n",
      "80. Training Perplexity: 2.8794615972672923e+23\n",
      "\n",
      "100. Training Accuracy: 85.00 %\n",
      "100. Training Perplexity: 2.4223566115277353e+24\n",
      "\n",
      "120. Training Accuracy: 87.00 %\n",
      "120. Training Perplexity: 1.0611110655761392e+19\n",
      "\n",
      "140. Training Accuracy: 83.00 %\n",
      "140. Training Perplexity: 2.317272155337238e+22\n",
      "\n",
      "160. Training Accuracy: 87.00 %\n",
      "160. Training Perplexity: 1.447736097315584e+21\n",
      "\n",
      "180. Training Accuracy: 82.00 %\n",
      "180. Training Perplexity: 9.21794596107026e+21\n",
      "\n",
      "200. Training Accuracy: 84.00 %\n",
      "200. Training Perplexity: 4.975306095768902e+23\n",
      "\n",
      "220. Training Accuracy: 83.00 %\n",
      "220. Training Perplexity: 7.877540129645407e+25\n",
      "\n",
      "240. Training Accuracy: 76.00 %\n",
      "240. Training Perplexity: 2.1143350477771228e+27\n",
      "\n",
      "260. Training Accuracy: 79.00 %\n",
      "260. Training Perplexity: 1.8771538180896913e+21\n",
      "\n",
      "280. Training Accuracy: 84.00 %\n",
      "280. Training Perplexity: 1.2286415180714075e+24\n",
      "\n",
      "300. Training Accuracy: 83.00 %\n",
      "300. Training Perplexity: 3.823633631072071e+25\n",
      "\n",
      "320. Training Accuracy: 82.00 %\n",
      "320. Training Perplexity: 7.3418546429098e+25\n",
      "\n",
      "340. Training Accuracy: 73.00 %\n",
      "340. Training Perplexity: 5.706458656134777e+33\n",
      "\n",
      "360. Training Accuracy: 79.00 %\n",
      "360. Training Perplexity: 8.234273554161581e+25\n",
      "\n",
      "380. Training Accuracy: 77.00 %\n",
      "380. Training Perplexity: 2.6974413653059342e+19\n",
      "\n",
      "400. Training Accuracy: 79.00 %\n",
      "400. Training Perplexity: 7.091628970515842e+20\n",
      "\n",
      "420. Training Accuracy: 85.00 %\n",
      "420. Training Perplexity: 7.368715084579463e+19\n",
      "\n",
      "440. Training Accuracy: 77.00 %\n",
      "440. Training Perplexity: 1.2758693078071469e+26\n",
      "\n",
      "460. Training Accuracy: 79.00 %\n",
      "460. Training Perplexity: 6.837160897441734e+28\n",
      "\n",
      "Epoch: 3/10\n",
      "0. Training Accuracy: 83.00 %\n",
      "0. Training Perplexity: 3.125769775998024e+17\n",
      "\n",
      "20. Training Accuracy: 80.00 %\n",
      "20. Training Perplexity: 4.784816785155583e+16\n",
      "\n",
      "40. Training Accuracy: 90.00 %\n",
      "40. Training Perplexity: 1.229399181605211e+16\n",
      "\n",
      "60. Training Accuracy: 89.00 %\n",
      "60. Training Perplexity: 2.9563679124151103e+24\n",
      "\n",
      "80. Training Accuracy: 89.00 %\n",
      "80. Training Perplexity: 1.0111250277639659e+17\n",
      "\n",
      "100. Training Accuracy: 85.00 %\n",
      "100. Training Perplexity: 1.4358572518214029e+17\n",
      "\n",
      "120. Training Accuracy: 94.00 %\n",
      "120. Training Perplexity: 3.7104701151682793e+21\n",
      "\n",
      "140. Training Accuracy: 86.00 %\n",
      "140. Training Perplexity: 4.837054079028769e+17\n",
      "\n",
      "160. Training Accuracy: 84.00 %\n",
      "160. Training Perplexity: 9.931715557284319e+17\n",
      "\n",
      "180. Training Accuracy: 81.00 %\n",
      "180. Training Perplexity: 1.3178151410709894e+21\n",
      "\n",
      "200. Training Accuracy: 85.00 %\n",
      "200. Training Perplexity: 7.011649318703235e+21\n",
      "\n",
      "220. Training Accuracy: 83.00 %\n",
      "220. Training Perplexity: 2.6426817366509367e+22\n",
      "\n",
      "240. Training Accuracy: 80.00 %\n",
      "240. Training Perplexity: 2.550595600776489e+23\n",
      "\n",
      "260. Training Accuracy: 85.00 %\n",
      "260. Training Perplexity: 1.0026533411897377e+19\n",
      "\n",
      "280. Training Accuracy: 82.00 %\n",
      "280. Training Perplexity: 5.761854940443303e+24\n",
      "\n",
      "300. Training Accuracy: 79.00 %\n",
      "300. Training Perplexity: 6.799987887447283e+18\n",
      "\n",
      "320. Training Accuracy: 81.00 %\n",
      "320. Training Perplexity: 9.033566312709616e+16\n",
      "\n",
      "340. Training Accuracy: 77.00 %\n",
      "340. Training Perplexity: 2.2258704661136936e+23\n",
      "\n",
      "360. Training Accuracy: 84.00 %\n",
      "360. Training Perplexity: 3.1573171338229535e+25\n",
      "\n",
      "380. Training Accuracy: 87.00 %\n",
      "380. Training Perplexity: 1.3766004327608546e+17\n",
      "\n",
      "400. Training Accuracy: 87.00 %\n",
      "400. Training Perplexity: 2.0371026020545908e+16\n",
      "\n",
      "420. Training Accuracy: 88.00 %\n",
      "420. Training Perplexity: 312823003819830.2\n",
      "\n",
      "440. Training Accuracy: 81.00 %\n",
      "440. Training Perplexity: 4.960619061892745e+27\n",
      "\n",
      "460. Training Accuracy: 81.00 %\n",
      "460. Training Perplexity: 1.3462924294977962e+20\n",
      "\n",
      "Epoch: 4/10\n",
      "0. Training Accuracy: 88.00 %\n",
      "0. Training Perplexity: 5062916840499.62\n",
      "\n",
      "20. Training Accuracy: 90.00 %\n",
      "20. Training Perplexity: 2410996547422.603\n",
      "\n",
      "40. Training Accuracy: 84.00 %\n",
      "40. Training Perplexity: 5.082559005611803e+17\n",
      "\n",
      "60. Training Accuracy: 89.00 %\n",
      "60. Training Perplexity: 8.840800765043286e+19\n",
      "\n",
      "80. Training Accuracy: 91.00 %\n",
      "80. Training Perplexity: 7.770690771750732e+17\n",
      "\n",
      "100. Training Accuracy: 84.00 %\n",
      "100. Training Perplexity: 1.5331040816643465e+19\n",
      "\n",
      "120. Training Accuracy: 80.00 %\n",
      "120. Training Perplexity: 5.8873404520719256e+16\n",
      "\n",
      "140. Training Accuracy: 80.00 %\n",
      "140. Training Perplexity: 6474341722185749.0\n",
      "\n",
      "160. Training Accuracy: 92.00 %\n",
      "160. Training Perplexity: 8415074284695731.0\n",
      "\n",
      "180. Training Accuracy: 88.00 %\n",
      "180. Training Perplexity: 101514214246030.78\n",
      "\n",
      "200. Training Accuracy: 85.00 %\n",
      "200. Training Perplexity: 381050988536445.4\n",
      "\n",
      "220. Training Accuracy: 88.00 %\n",
      "220. Training Perplexity: 7746504518902407.0\n",
      "\n",
      "240. Training Accuracy: 82.00 %\n",
      "240. Training Perplexity: 1.4164351179167547e+20\n",
      "\n",
      "260. Training Accuracy: 84.00 %\n",
      "260. Training Perplexity: 4.3833418424034323e+17\n",
      "\n",
      "280. Training Accuracy: 81.00 %\n",
      "280. Training Perplexity: 7.212602002788055e+18\n",
      "\n",
      "300. Training Accuracy: 90.00 %\n",
      "300. Training Perplexity: 1.2665556374112467e+20\n",
      "\n",
      "320. Training Accuracy: 80.00 %\n",
      "320. Training Perplexity: 2.2341755787895692e+24\n",
      "\n",
      "340. Training Accuracy: 84.00 %\n",
      "340. Training Perplexity: 9.402450124553882e+17\n",
      "\n",
      "360. Training Accuracy: 91.00 %\n",
      "360. Training Perplexity: 3.7512568934508303e+18\n",
      "\n",
      "380. Training Accuracy: 90.00 %\n",
      "380. Training Perplexity: 3863422722718940.5\n",
      "\n",
      "400. Training Accuracy: 90.00 %\n",
      "400. Training Perplexity: 7.693888980512472e+16\n",
      "\n",
      "420. Training Accuracy: 90.00 %\n",
      "420. Training Perplexity: 4041171211987.9375\n",
      "\n",
      "440. Training Accuracy: 81.00 %\n",
      "440. Training Perplexity: 4.335596743613272e+19\n",
      "\n",
      "460. Training Accuracy: 87.00 %\n",
      "460. Training Perplexity: 5.037123858077953e+19\n",
      "\n",
      "Epoch: 5/10\n",
      "0. Training Accuracy: 88.00 %\n",
      "0. Training Perplexity: 144689105858.58368\n",
      "\n",
      "20. Training Accuracy: 83.00 %\n",
      "20. Training Perplexity: 1.9693493522777146e+17\n",
      "\n",
      "40. Training Accuracy: 92.00 %\n",
      "40. Training Perplexity: 3874573631458458.0\n",
      "\n",
      "60. Training Accuracy: 89.00 %\n",
      "60. Training Perplexity: 7.29932161934117e+16\n",
      "\n",
      "80. Training Accuracy: 90.00 %\n",
      "80. Training Perplexity: 2.8271648798482458e+17\n",
      "\n",
      "100. Training Accuracy: 82.00 %\n",
      "100. Training Perplexity: 567242762609377.2\n",
      "\n",
      "120. Training Accuracy: 88.00 %\n",
      "120. Training Perplexity: 7790565157677277.0\n",
      "\n",
      "140. Training Accuracy: 92.00 %\n",
      "140. Training Perplexity: 1.1673187042841221e+19\n",
      "\n",
      "160. Training Accuracy: 89.00 %\n",
      "160. Training Perplexity: 3479943273908.328\n",
      "\n",
      "180. Training Accuracy: 90.00 %\n",
      "180. Training Perplexity: 1.5777558050377718e+16\n",
      "\n",
      "200. Training Accuracy: 91.00 %\n",
      "200. Training Perplexity: 1015985425869.7893\n",
      "\n",
      "220. Training Accuracy: 88.00 %\n",
      "220. Training Perplexity: 8.321047990102699e+18\n",
      "\n",
      "240. Training Accuracy: 80.00 %\n",
      "240. Training Perplexity: 2.933812396346805e+23\n",
      "\n",
      "260. Training Accuracy: 84.00 %\n",
      "260. Training Perplexity: 67721325539592.65\n",
      "\n",
      "280. Training Accuracy: 92.00 %\n",
      "280. Training Perplexity: 2.91437118219414e+22\n",
      "\n",
      "300. Training Accuracy: 85.00 %\n",
      "300. Training Perplexity: 1.38097894136912e+17\n",
      "\n",
      "320. Training Accuracy: 81.00 %\n",
      "320. Training Perplexity: 4.354404335588897e+17\n",
      "\n",
      "340. Training Accuracy: 83.00 %\n",
      "340. Training Perplexity: 74035783367870.39\n",
      "\n",
      "360. Training Accuracy: 84.00 %\n",
      "360. Training Perplexity: 1.038567278067533e+18\n",
      "\n",
      "380. Training Accuracy: 88.00 %\n",
      "380. Training Perplexity: 159024970031526.56\n",
      "\n",
      "400. Training Accuracy: 91.00 %\n",
      "400. Training Perplexity: 6732317870146961.0\n",
      "\n",
      "420. Training Accuracy: 84.00 %\n",
      "420. Training Perplexity: 31347259173672.48\n",
      "\n",
      "440. Training Accuracy: 89.00 %\n",
      "440. Training Perplexity: 1.6922943247546294e+17\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3dcca7a7e7d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mipoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ipochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\tensorflow_tuts\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\tensorflow_tuts\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\tensorflow_tuts\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\tensorflow_tuts\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\envs\\tensorflow_tuts\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size, num_steps = 100, seq_len # maxlen size sentence and 100 of them, num_steps: step of words\n",
    "_epochs = 10\n",
    "_ipochs = 4\n",
    "for epoch in range(_epochs):\n",
    "    print('Epoch: {}/{}'.format(epoch, _epochs))\n",
    "    for step, (_x, _y) in enumerate(ptb_reader.ptb_iterator(train_data, batch_size, num_steps)):\n",
    "        _y = _y[:, -1]\n",
    "        y = one_hot(_x, _y, seq_len)\n",
    "        for ipoch in range(_ipochs):\n",
    "            sess.run(minimize, feed_dict={data: _x, target: y})\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={data: _x, target: y})\n",
    "            perplexity = 2**(sess.run(loss, feed_dict={data: _x, target: y}))\n",
    "            print('{}. Training Accuracy: {:0.2F} %'.format(step, float(acc)*100))\n",
    "            print('{}. Training Perplexity: {}\\n'.format(step, perplexity))\n",
    "            save_path = saver.save(sess, \"saved_model/model.ckpt\")\n",
    "            #print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Test Accuracy: 7.10 %\n",
      "1. Test Accuracy: 8.30 %\n",
      "2. Test Accuracy: 7.90 %\n",
      "3. Test Accuracy: 6.90 %\n"
     ]
    }
   ],
   "source": [
    "batch_size, num_steps = 1000, seq_len # maxlen size sentence and 100 of them, num_steps: step of words\n",
    "for step, (_tx, _ty) in enumerate(ptb_reader.ptb_iterator(test_data, batch_size, num_steps)):\n",
    "    _ty = _ty[:, -1]\n",
    "    ty = one_hot(_tx, _ty, seq_len)\n",
    "    acc = sess.run(accuracy, feed_dict={data: _tx, target: ty})\n",
    "    print('{}. Test Accuracy: {:0.2F} %'.format(step, float(acc)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8, 243,  16,  47,  34], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = sess.run(predict, feed_dict={data: _tx})\n",
    "np.argmax(y_hat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 997,    1,    2,   47, 4903])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  60,  111,   15, 2988,    1,  442,  232,   70,   18,    1,  125,\n",
       "         584,    2,    1,  558,    1,  141,    4, 2195, 5555],\n",
       "       [  91,    6, 1135,  402,    7,    1, 8204,    2,   10,  862,   75,\n",
       "         863,   54,    7,    1, 6986,    8,    0,   61,    7],\n",
       "       [ 137,   26,  524, 5146,   11,   39,   96,    2, 1706,   90, 1968,\n",
       "           4,    0, 5284,   47,   39, 1108, 9215,    0,    1],\n",
       "       [1006,    0, 1422,  353,    2,   39,   93, 2102,    1, 3327,    2,\n",
       "          78,   73,  314,    6,  260,   72,  195,    0,   60],\n",
       "       [  93, 8014,    6,   45, 1173, 1874,    5,    0,   98,    8,    0,\n",
       "         197,    1,    2, 1243,  456, 3459,   10,   38,   26]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tx"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
